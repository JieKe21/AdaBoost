{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdaBoost Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ud8xSqFag5Z"
      },
      "source": [
        "# Build AdaBoost Model from scratch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkSefHmOEbl6"
      },
      "source": [
        "from numpy import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS5Mh9RTPjIz"
      },
      "source": [
        "## Step 1. Build AdaBoost Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkphqwgZQMXQ"
      },
      "source": [
        "### 1.1 Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4D7nXxeEo42"
      },
      "source": [
        "# generate a simple dataset\n",
        "def loadSimpData():\n",
        "    \"\"\" Test Data\n",
        "    Returns:\n",
        "        dataArr  \n",
        "        labelArr\n",
        "    \"\"\"\n",
        "    dataArr = array([[1., 2.1], [2., 1.1], [1.3, 1.], [1., 1.], [2., 1.]])\n",
        "    labelArr = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
        "    return dataArr, labelArr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnDlEHfBE0Cz"
      },
      "source": [
        "# general function to parse tab -delimited floats\n",
        "def loadDataSet(fileName):\n",
        "    # get number of fields\n",
        "    numFeat = len(open(fileName).readline().split('\\t'))\n",
        "    dataArr = []\n",
        "    labelArr = []\n",
        "    fr = open(fileName)\n",
        "    for line in fr.readlines():\n",
        "        lineArr = []\n",
        "        curLine = line.strip().split('\\t')\n",
        "        for i in range(numFeat-1):\n",
        "            lineArr.append(float(curLine[i]))\n",
        "        dataArr.append(lineArr)\n",
        "        labelArr.append(float(curLine[-1]))\n",
        "    return dataArr, labelArr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK3FZlWJQfQE"
      },
      "source": [
        "### 1.2 Build Weak Classifier (Decision stump-generating functions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0Z6688RE5qc"
      },
      "source": [
        "def stumpClassify(dataMat, dimen, threshVal, threshIneq):\n",
        "    \"\"\"stumpClassify\n",
        "    Args:\n",
        "        dataMat    Matrix\n",
        "        dimen     Feature Column\n",
        "        threshVal   The value needed to be compared\n",
        "    Returns:\n",
        "        retArray \n",
        "    \"\"\"\n",
        "    # Default num is 1\n",
        "    retArray = ones((shape(dataMat)[0], 1))\n",
        "    # dataMat[:, dimen] shows all values in Column [dimen]\n",
        "\n",
        "    if threshIneq == 'lt':\n",
        "        retArray[dataMat[:, dimen] <= threshVal] = -1.0\n",
        "    else:\n",
        "        retArray[dataMat[:, dimen] > threshVal] = -1.0\n",
        "    return retArray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErYG-P36E-MX"
      },
      "source": [
        "def buildStump(dataArr, labelArr, D):\n",
        "    \"\"\"buildStump(Decision Stump)\n",
        "    Args:\n",
        "        dataArr   \n",
        "        labelArr  \n",
        "        D         The weight vector\n",
        "    Returns:\n",
        "        bestStump    Best Decision Stump model\n",
        "        minError    Minimum Error rate\n",
        "        bestClasEst  The result set after training\n",
        "    \"\"\"\n",
        "    # Data Transform\n",
        "    dataMat = mat(dataArr)\n",
        "    labelMat = mat(labelArr).T\n",
        "    # Row m, Column n\n",
        "    m, n = shape(dataMat)\n",
        "\n",
        "    # Initialize Data\n",
        "    numSteps = 10.0\n",
        "    bestStump = {}\n",
        "    bestClasEst = mat(zeros((m, 1)))\n",
        "    # Initialized minError is infinite\n",
        "    minError = inf\n",
        "\n",
        "    # Circulate all feature columns\n",
        "    for i in range(n):\n",
        "        rangeMin = dataMat[:, i].min()\n",
        "        rangeMax = dataMat[:, i].max()\n",
        "        # print 'rangeMin=%s, rangeMax=%s' % (rangeMin, rangeMax)\n",
        "        stepSize = (rangeMax-rangeMin)/numSteps\n",
        "        for j in range(-1, int(numSteps)+1):\n",
        "            # go over less than and greater than\n",
        "            for inequal in ['lt', 'gt']:\n",
        "                # if -1, then get rangeMin-stepSize; if numSteps, then get rangeMax\n",
        "                threshVal = (rangeMin + float(j) * stepSize)\n",
        "                # Use decision stumpe model to get classification\n",
        "                predictedVals = stumpClassify(dataMat, i, threshVal, inequal)\n",
        "                # print predictedVals\n",
        "                errArr = mat(ones((m, 1)))\n",
        "                # Correct is 0, while wrong is 1\n",
        "                errArr[predictedVals == labelMat] = 0\n",
        "                weightedError = D.T*errArr\n",
        "                '''\n",
        "                dim         represent feature columns\n",
        "                threshVal      threshold value of tree\n",
        "                inequal       represent the situation when not equal\n",
        "                weightedError  show error rate of all results\n",
        "                bestClasEst   best predicted result\n",
        "                '''\n",
        "                # print \"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError)\n",
        "                if weightedError < minError:\n",
        "                    minError = weightedError\n",
        "                    bestClasEst = predictedVals.copy()\n",
        "                    bestStump['dim'] = i\n",
        "                    bestStump['thresh'] = threshVal\n",
        "                    bestStump['ineq'] = inequal\n",
        "    return bestStump, minError, bestClasEst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wacqOZctRxV9"
      },
      "source": [
        "### 1.3 AdaBoost Training with Decision stumps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zdmVkvsFGzq"
      },
      "source": [
        "def adaBoostTrainDS(dataArr, labelArr, numIt=40):\n",
        "    \"\"\"adaBoostTrainDS\n",
        "    Args:\n",
        "        dataArr   \n",
        "        labelArr  \n",
        "        numIt    \n",
        "    Returns:\n",
        "        weakClassArr  set of weak classifiers\n",
        "        aggClassEst   predicted results of classification\n",
        "    \"\"\"\n",
        "    weakClassArr = []\n",
        "    m = shape(dataArr)[0]\n",
        "    D = mat(ones((m, 1))/m)\n",
        "    aggClassEst = mat(zeros((m, 1)))\n",
        "    for i in range(numIt):\n",
        "        # get the decision stump model\n",
        "        bestStump, error, classEst = buildStump(dataArr, labelArr, D)\n",
        "\n",
        "        # The alpha values are based on the error of each weak classifier\n",
        "        # calculate alpha value\n",
        "        alpha = float(0.5*log((1.0-error)/max(error, 1e-16)))\n",
        "        bestStump['alpha'] = alpha\n",
        "        # store Stump Params in Array\n",
        "        weakClassArr.append(bestStump)\n",
        "\n",
        "        # print \"alpha=%s, classEst=%s, bestStump=%s, error=%s \" % (alpha, classEst.T, bestStump, error)\n",
        "        expon = multiply(-1*alpha*mat(labelArr).T, classEst)\n",
        "        # print '\\n'\n",
        "        # print 'labelArr=', labelArr\n",
        "        # print 'classEst=', classEst.T\n",
        "        # print '\\n'\n",
        "        # print 'multi: ', multiply(mat(labelArr).T, classEst).T\n",
        "        D = multiply(D, exp(expon))\n",
        "        D = D/D.sum()\n",
        "        # print \"D: \", D.T\n",
        "        # print '\\n'\n",
        "\n",
        "        aggClassEst += alpha*classEst\n",
        "        # use sign() function to make positive number as 1, negative number as -1, and 0 as 0\n",
        "        aggErrors = multiply(sign(aggClassEst) != mat(labelArr).T, ones((m, 1)))\n",
        "        errorRate = aggErrors.sum()/m\n",
        "        # print \"total error=%s \" % (errorRate)\n",
        "        if errorRate == 0.0:\n",
        "            break\n",
        "    return weakClassArr, aggClassEst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mDv52dVSBoI"
      },
      "source": [
        "### 1.4 AdaBoost Classification Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utHIixbqFKJZ"
      },
      "source": [
        "def adaClassify(datToClass, classifierArr):\n",
        "    # do stuff similar to last aggClassEst in adaBoostTrainDS\n",
        "    dataMat = mat(datToClass)\n",
        "    m = shape(dataMat)[0]\n",
        "    aggClassEst = mat(zeros((m, 1)))\n",
        "\n",
        "    # Circulate different classifiers\n",
        "    for i in range(len(classifierArr)):\n",
        "        classEst = stumpClassify(dataMat, classifierArr[i]['dim'], classifierArr[i]['thresh'], classifierArr[i]['ineq'])\n",
        "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
        "        # print aggClassEst\n",
        "    return sign(aggClassEst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZFVxdOiSQt3"
      },
      "source": [
        "### 1.5 ROC plotting and AUC calculating function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnH4NqE4FMn0"
      },
      "source": [
        "def plotROC(predStrengths, classLabels):\n",
        "    \"\"\"plotROC(Print the ROC curve and calculate the AUC (area under the curve))\n",
        "    Args:\n",
        "        predStrengths  Weighted values of predicted results\n",
        "        classLabels   Original set of labels\n",
        "    \"\"\"\n",
        "    print('predStrengths=', predStrengths)\n",
        "    print('classLabels=', classLabels)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    # variable to calculate AUC\n",
        "    ySum = 0.0\n",
        "    # Sum positive samples\n",
        "    numPosClas = sum(array(classLabels)==1.0)\n",
        "    # Percentage of positive samples\n",
        "    yStep = 1/float(numPosClas)\n",
        "    # Percentage of negative samples\n",
        "    xStep = 1/float(len(classLabels)-numPosClas)\n",
        "    # Use argsort() function to get sorted index, it's reverse\n",
        "    sortedIndicies = predStrengths.argsort()\n",
        "    # Test the sequence of the results\n",
        "    print('sortedIndicies=', sortedIndicies, predStrengths[0, 176], predStrengths.min(), predStrengths[0, 293], predStrengths.max())\n",
        "\n",
        "    # create figures for the plot\n",
        "    fig = plt.figure()\n",
        "    fig.clf()\n",
        "    ax = plt.subplot(111)\n",
        "    # cursor\n",
        "    cur = (1.0, 1.0)\n",
        "    # loop through all the values, drawing a line segment at each point\n",
        "    for index in sortedIndicies.tolist()[0]:\n",
        "        if classLabels[index] == 1.0:\n",
        "            delX = 0\n",
        "            delY = yStep\n",
        "        else:\n",
        "            delX = xStep\n",
        "            delY = 0\n",
        "            ySum += cur[1]\n",
        "        # draw line from cur to (cur[0]-delX, cur[1]-delY)\n",
        "        print(cur[0], cur[0]-delX, cur[1], cur[1]-delY)\n",
        "        ax.plot([cur[0], cur[0]-delX], [cur[1], cur[1]-delY], c='b')\n",
        "        cur = (cur[0]-delX, cur[1]-delY)\n",
        "    # draw diagonal dotted line \n",
        "    ax.plot([0, 1], [0, 1], 'b--')\n",
        "    plt.xlabel('False positive rate')\n",
        "    plt.ylabel('True positive rate')\n",
        "    plt.title('ROC curve for AdaBoost horse colic detection system')\n",
        "    # set the drawing area\n",
        "    ax.axis([0, 1, 0, 1])\n",
        "    plt.show()\n",
        "    print(\"the Area Under the Curve is: \", ySum*xStep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNcv7KWdS1RM"
      },
      "source": [
        "## Step 2. AdaBoost on a simple dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0n-PKzYFQJc"
      },
      "source": [
        "# Simple Dataset\n",
        "\n",
        "# Classify 5 dots\n",
        "dataArr, labelArr = loadSimpData()\n",
        "print('dataArr:\\n', dataArr, '\\nlabelArr:', labelArr)\n",
        "\n",
        "# Initialized D value\n",
        "# weightedError = D.T*errArr\n",
        "D = mat(ones((5, 1))/5)\n",
        "print('\\nD=', D.T)\n",
        "\n",
        "bestStump, minError, bestClasEst = buildStump(dataArr, labelArr, D)\n",
        "print('\\nbestStump =', bestStump)\n",
        "print('\\nminError =', minError)\n",
        "print('\\nbestClasEst =', bestClasEst.T)\n",
        "\n",
        "# weakClassArr\n",
        "weakClassArr, aggClassEst = adaBoostTrainDS(dataArr, labelArr, 9)\n",
        "print('\\nweakClassArr =', weakClassArr, '\\naggClassEst =', aggClassEst.T)\n",
        "\n",
        "# Results\n",
        "print(adaClassify([0, 0], weakClassArr).T)\n",
        "print(adaClassify([[5, 5], [0, 0]], weakClassArr).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9gdGksAS-3Y"
      },
      "source": [
        "## Step 3. AdaBoost on a difficult dataset (Horse Colic Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKs9q8SHTKF5"
      },
      "source": [
        "### 3.1 Train Classifiers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyXX2kcwHNq-"
      },
      "source": [
        "# Difficult Dataset (Horse Colic Dataset)\n",
        "# Training Set\n",
        "dataArr, labelArr = loadDataSet(\"drive/MyDrive/horseColicTraining2.txt\")\n",
        "weakClassArr, aggClassEst = adaBoostTrainDS(dataArr, labelArr, 40)\n",
        "print(weakClassArr, \n",
        "      '\\n-------------------------------------------------------------------\\n', aggClassEst.T, \n",
        "      '\\n-------------------------------------------------------------------\\n')\n",
        "\n",
        "# Get ROC and AUC\n",
        "plotROC(aggClassEst.T, labelArr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVanwuT5VlKF"
      },
      "source": [
        "### 3.2 Test the AdaBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_fxslq8IMlB"
      },
      "source": [
        "# Test Set\n",
        "dataArrTest, labelArrTest = loadDataSet(\"drive/MyDrive/horseColicTest2.txt\")\n",
        "m = shape(dataArrTest)[0]\n",
        "predicting10 = adaClassify(dataArrTest, weakClassArr)\n",
        "errArr = mat(ones((m, 1)))\n",
        "# Test result: The number of samples, The number of wrong predictions, Error Rate\n",
        "print('The Number of Test Samples:', m, \n",
        "    '\\nThe Number of Wrong Predictions:', errArr[predicting10 != mat(labelArrTest).T].sum(), \n",
        "    '\\nError Rate:', errArr[predicting10 != mat(labelArrTest).T].sum()/m)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}